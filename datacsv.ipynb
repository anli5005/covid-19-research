{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "from getcasedata import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "60941.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/anli5005/HOMEDISK/Research/COVID-19/control/getstatedata2.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = np.diff(np.append(np.array([0], dtype=np.float32), data[data[\"state\"] == state][data[\"date\"] >= \"2020-03-01\"][\"cases\"].to_numpy(dtype=np.float32)))\n"
     ]
    }
   ],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "data = get_data(False)\n",
    "data.keys()\n",
    "cases_np = None\n",
    "log_cases_np = None\n",
    "log_diff_cases_np = None\n",
    "diff_cases_np = None\n",
    "for state in data.keys():\n",
    "    data[state] = np.concatenate((data[state][:6], moving_average(data[state], 7)))\n",
    "    diff_state_np = np.diff(np.append(np.array([0], dtype=np.float32), data[state]))\n",
    "    log_state_np = np.log(np.clip(data[state], 1, None))\n",
    "    log_diff_state_np = np.diff(np.append(np.array([0], dtype=np.float32), log_state_np))\n",
    "    if cases_np is None:\n",
    "        cases_np = data[state]\n",
    "        diff_cases_np = diff_state_np\n",
    "        log_cases_np = log_state_np\n",
    "        log_diff_cases_np = log_diff_state_np\n",
    "    else:\n",
    "        cases_np = np.concatenate((cases_np, data[state]))\n",
    "        diff_cases_np = np.concatenate((diff_cases_np, diff_state_np))\n",
    "        log_cases_np = np.concatenate((log_cases_np, log_state_np))\n",
    "        log_diff_cases_np = np.concatenate((log_diff_cases_np, log_diff_state_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_df = pd.read_csv(\"state-abbreviations.csv\") # Columns Code and State - maps state codes to state names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15889,)\n",
      "[5.62857143e+02 5.80142857e+02 5.87142857e+02 5.80428571e+02\n",
      " 5.71428571e+02 5.80428571e+02 6.59571429e+02 6.52571429e+02\n",
      " 6.58714286e+02 6.70857143e+02 6.90142857e+02 6.96571429e+02\n",
      " 7.22571429e+02 6.47714286e+02 6.50857143e+02 6.46571429e+02\n",
      " 6.65142857e+02 6.74000000e+02 6.95285714e+02 7.24285714e+02\n",
      " 7.31571429e+02 7.48714286e+02 7.69142857e+02 8.14857143e+02\n",
      " 8.29714286e+02 8.34142857e+02 9.13428571e+02 9.48857143e+02\n",
      " 1.03228571e+03 1.10157143e+03 1.17571429e+03 1.23428571e+03\n",
      " 1.31442857e+03 1.39614286e+03 1.49757143e+03 1.39928571e+03\n",
      " 1.60185714e+03 1.72285714e+03 1.77028571e+03 1.86500000e+03\n",
      " 2.00600000e+03 2.11885714e+03 2.23214286e+03 2.18514286e+03\n",
      " 2.15257143e+03 2.15414286e+03 2.04828571e+03 2.39057143e+03\n",
      " 2.47300000e+03 2.67085714e+03 2.42042857e+03 2.56842857e+03\n",
      " 2.57785714e+03 2.66142857e+03 2.40557143e+03 2.39071429e+03\n",
      " 2.38885714e+03 2.60200000e+03 2.50400000e+03 2.47757143e+03\n",
      " 2.45314286e+03 2.75614286e+03 2.83128571e+03 2.86342857e+03\n",
      " 3.00771429e+03 3.10371429e+03 3.33142857e+03 3.41142857e+03\n",
      " 2.98200000e+03 2.75671429e+03 2.47671429e+03 2.77842857e+03\n",
      " 2.87285714e+03 2.73600000e+03 2.52342857e+03 3.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(cases_np.shape)\n",
    "print(cases_np[220:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_df = pd.read_csv(\"tsa.csv\")\n",
    "tsa = []\n",
    "for idx, row in iter(tsa_df.iterrows()):\n",
    "    tsa.append(int(row[\"year\"].replace(\",\", \"\")))\n",
    "tsa = np.array(list(reversed(tsa)), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n"
     ]
    }
   ],
   "source": [
    "svi = pd.read_csv(\"svi.csv\")\n",
    "svis = {}\n",
    "min_svi = 100000\n",
    "max_svi = 0\n",
    "for i, row in svi.iterrows():\n",
    "    state = row[\"LOCATION\"].split(\", \")[1]\n",
    "    if state not in svis:\n",
    "        svis[state] = []\n",
    "    if not math.isnan(row[\"SPL_THEMES\"]):\n",
    "        s = row[\"SPL_THEMES\"]\n",
    "        if s != -999:\n",
    "            svis[state].append(s)\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Processed %d\" % i)\n",
    "for key in svis.keys():\n",
    "    svis[key] = np.mean(np.array(svis[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 10000\n",
      "Processed 20000\n",
      "Processed 30000\n",
      "Processed 40000\n",
      "Processed 50000\n",
      "Processed 60000\n",
      "Processed 70000\n",
      "Processed 80000\n",
      "Processed 90000\n",
      "Processed 100000\n",
      "Processed 110000\n",
      "Processed 120000\n",
      "Processed 130000\n",
      "Processed 140000\n",
      "Processed 150000\n",
      "Processed 160000\n",
      "Processed 170000\n",
      "Processed 180000\n",
      "Processed 190000\n",
      "Processed 200000\n",
      "Processed 210000\n",
      "Processed 220000\n"
     ]
    }
   ],
   "source": [
    "fips = pd.read_csv(\"cbg_fips_codes.csv\")\n",
    "states = {}\n",
    "state_names = fips[\"state\"].unique()\n",
    "state_fips = fips[\"state_fips\"].unique()\n",
    "for n, f in zip(state_names, state_fips):\n",
    "    states[f] = n\n",
    "pop = pd.read_csv(\"cbg_b00.csv\")\n",
    "pops = {}\n",
    "for i, row in pop.iterrows():\n",
    "    state = states[int(str(row[\"census_block_group\"])[:-12])]\n",
    "    if state not in pops:\n",
    "        pops[state] = 0\n",
    "    if not math.isnan(row[\"B00001e1\"]):\n",
    "        pops[state] += row.astype(\"int\")[\"B00001e1\"]\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Processed %d\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv(\"area.csv\")\n",
    "pop_dens = {}\n",
    "for k in pops.keys():\n",
    "    try:\n",
    "        name = next(iter(abbr_df[abbr_df[\"Code\"] == k].iterrows()))[1][\"State\"]\n",
    "        pop_dens[name] = pops[k] / int(next(iter(area[area[\"State\"] == name].iterrows()))[1][\"Land Area\"].replace(\",\", \"\"))\n",
    "    except StopIteration:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(\"temperature-all-states.csv\")\n",
    "temp = {}\n",
    "for idx, row in iter(temp_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in temp:\n",
    "            temp[state] = []\n",
    "        temp[state].append(row[\"temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df = pd.read_csv(\"flu-season-all-states.csv\")\n",
    "flu = {}\n",
    "for idx, row in iter(flu_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in flu:\n",
    "            flu[state] = []\n",
    "        flu[state].append(row[\"season\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_dist_df = pd.read_csv(\"social-distance-all-states.csv\")\n",
    "social_dist = {}\n",
    "for idx, row in iter(social_dist_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in social_dist:\n",
    "            social_dist[state] = []\n",
    "        social_dist[state].append(row[\"soc_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stay_home_df = pd.read_csv(\"stay-home-all-states.csv\")\n",
    "stay_home = {}\n",
    "for idx, row in iter(stay_home_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in stay_home:\n",
    "            stay_home[state] = []\n",
    "        stay_home[state].append(row[\"change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_traffic_df = pd.read_csv(\"foot-traffic-all-states.csv\")\n",
    "foot_traffic = {}\n",
    "for idx, row in iter(foot_traffic_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in foot_traffic:\n",
    "            foot_traffic[state] = []\n",
    "        foot_traffic[state].append(row[\"change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitalized_df = pd.read_csv(\"all-states-history.csv\")\n",
    "hospitalized = {}\n",
    "for idx, row in iter(hospitalized_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        try:\n",
    "            state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state\"]].iterrows()))[1][\"State\"]\n",
    "        except StopIteration:\n",
    "            continue\n",
    "        if state not in hospitalized:\n",
    "            hospitalized[state] = []\n",
    "        hospitalized[state].append(row[\"hospitalizedIncrease\"])\n",
    "for state in hospitalized.keys():\n",
    "    hospitalized[state] = list(reversed(hospitalized[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_df = pd.read_csv(\"tests-all-states.csv\")\n",
    "tests = {}\n",
    "for idx, row in iter(tests_df.iterrows()):\n",
    "    if row[\"date\"] >= \"2020-03-01\":\n",
    "        state = next(iter(abbr_df[abbr_df[\"Code\"] == row[\"state_code\"]].iterrows()))[1][\"State\"]\n",
    "        if state not in tests:\n",
    "            tests[state] = []\n",
    "        tests[state].append(row[\"tests\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_file = open(\"safegraph/sums.json\")\n",
    "sg_raw = json.load(sg_file)\n",
    "sg_file.close()\n",
    "sg = [{}, {}, {}, {}, {}, {}]\n",
    "for typ in range(len(sg_raw)):\n",
    "    for key in sg_raw[typ].keys():\n",
    "        try:\n",
    "            state = next(iter(abbr_df[abbr_df[\"Code\"] == key].iterrows()))[1][\"State\"]\n",
    "            sg[typ][state] = sg_raw[typ][key][60:]\n",
    "        except StopIteration:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_buckets = np.percentile(cases_np, list(range(5, 100, 5)))\n",
    "log_case_buckets = np.percentile(log_cases_np, [20, 40, 60, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.77142857e+00 8.85714286e+00 2.54285714e+01 4.83714286e+01\n",
      " 7.94285714e+01 1.15571429e+02 1.65114286e+02 2.42714286e+02\n",
      " 3.28714286e+02 4.17285714e+02 5.32000000e+02 6.42771429e+02\n",
      " 7.51457143e+02 8.84571429e+02 1.08214286e+03 1.39417143e+03\n",
      " 1.90525714e+03 2.71788571e+03 4.73497143e+03]\n",
      "[3.87890827 5.49188497 6.46578915 7.24005555]\n"
     ]
    }
   ],
   "source": [
    "print(case_buckets)\n",
    "print(log_case_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_buckets(arr):\n",
    "    print(np.where(arr < 0))\n",
    "    return np.concatenate((np.percentile(arr[np.where(arr < 0)], [33, 67]), np.array([0], dtype=np.float32), np.percentile(arr[np.where(arr > 0)], [33, 67])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([    1,     5,    24, ..., 15882, 15883, 15884]),)\n",
      "(array([    1,     5,    24, ..., 15829, 15831, 15840]),)\n",
      "(5,)\n",
      "[-26.28571429  -4.71428571   0.           5.71428571  30.28571429]\n"
     ]
    }
   ],
   "source": [
    "diff_case_buckets = diff_buckets(diff_cases_np)\n",
    "log_diff_case_buckets = diff_buckets(log_diff_cases_np)\n",
    "print(diff_case_buckets.shape)\n",
    "print(diff_case_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with row 295\n",
      "Done with row 590\n",
      "Done with row 885\n",
      "Done with row 1180\n",
      "Done with row 1475\n",
      "Done with row 1770\n",
      "Done with row 2065\n",
      "Done with row 2360\n",
      "Done with row 2655\n",
      "Done with row 2950\n",
      "Done with row 3245\n",
      "Done with row 3540\n",
      "Done with row 3835\n",
      "Done with row 4129\n",
      "Done with row 4423\n",
      "Done with row 4716\n",
      "Done with row 5008\n",
      "Done with row 5299\n",
      "Done with row 5590\n",
      "Done with row 5881\n",
      "Done with row 6172\n",
      "Done with row 6462\n",
      "Done with row 6752\n",
      "Done with row 7042\n",
      "Done with row 7332\n",
      "Done with row 7622\n",
      "Done with row 7912\n",
      "Done with row 8202\n",
      "Done with row 8491\n",
      "Done with row 8780\n",
      "Done with row 9069\n",
      "Done with row 9358\n",
      "Done with row 9647\n",
      "Done with row 9935\n",
      "Done with row 10223\n",
      "Done with row 10510\n",
      "Done with row 10797\n",
      "Done with row 11083\n",
      "Done with row 11369\n",
      "Done with row 11654\n",
      "Done with row 11939\n",
      "Done with row 12224\n",
      "Done with row 12509\n",
      "Done with row 12794\n",
      "Done with row 13079\n",
      "Done with row 13363\n",
      "Done with row 13647\n",
      "Done with row 13930\n",
      "Done with row 14213\n",
      "Done with row 14496\n",
      "Done with row 14775\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"date\", \"state\", \"cases\", \"log_cases\", \"diff_cases\", \"diff_log_cases\", \"class\", \"log_class\", \"diff_class\", \"diff_log_class\", \"density\", \"svi\", \"tsa\", \"visits_hotels\", \"visits_restaurants\", \"visits_retail\", \"visits_personal_care\", \"visits_gyms\", \"visits_health\", \"temperature\", \"flu\", \"soc_dist\", \"tests\", \"hospitalized\"])\n",
    "row = 0\n",
    "for state in data.keys():\n",
    "    if state not in svis or state not in pop_dens or state not in sg[0] or state not in sg[1] or state not in sg[2] or state not in sg[3] or state not in sg[4]:\n",
    "        continue\n",
    "    d = data[state]\n",
    "    for i in range(0, d.shape[0]):\n",
    "        log = math.log(max(1, d[i]))\n",
    "        diff = d[i]\n",
    "        diff_log = log\n",
    "        if i > 0:\n",
    "            diff -= d[i - 1]\n",
    "            diff_log -= math.log(max(1, d[i - 1]))\n",
    "        df.loc[row] = [\n",
    "            i,\n",
    "            state,\n",
    "            d[i],\n",
    "            log,\n",
    "            diff,\n",
    "            diff_log,\n",
    "            next(filter(lambda j: case_buckets[j] > d[i] if j < len(case_buckets) else True, range(len(case_buckets) + 1))),\n",
    "            next(filter(lambda j: log_case_buckets[j] > log if j < len(log_case_buckets) else True, range(len(log_case_buckets) + 1))),\n",
    "            next(filter(lambda j: diff_case_buckets[j] > diff if j < len(diff_case_buckets) else True, range(len(diff_case_buckets) + 1))),\n",
    "            next(filter(lambda j: log_diff_case_buckets[j] > diff_log if j < len(log_diff_case_buckets) else True, range(len(log_diff_case_buckets) + 1))),\n",
    "            pop_dens[state],\n",
    "            svis[state],\n",
    "            tsa[i],\n",
    "            sg[0][state][i],\n",
    "            sg[1][state][i],\n",
    "            sg[2][state][i],\n",
    "            sg[3][state][i],\n",
    "            sg[4][state][i],\n",
    "            sg[5][state][i],\n",
    "            temp[state][i],\n",
    "            flu[state][i],\n",
    "            social_dist[state][i],\n",
    "            tests[state][i],\n",
    "            hospitalized[state][i]\n",
    "        ]\n",
    "        row += 1\n",
    "    if row % 1 == 0:\n",
    "        print(\"Done with row %d\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
